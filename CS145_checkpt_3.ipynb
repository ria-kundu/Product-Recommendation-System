{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehwzZ4z67U1q",
        "outputId": "c57268ed-45ef-40d7-bb2f-9b06e157d74f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch_geometric\n",
        "# from torch_geometric.data import HeteroData"
      ],
      "metadata": {
        "id": "D6he9MxFGJB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def get_full_df(dir_name):\n",
        "  folder_path = f\"/content/drive/MyDrive/updated_chckpt2_data/{dir_name}\"\n",
        "  csv_files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
        "\n",
        "  dfs = []\n",
        "  for file in csv_files:\n",
        "      file_path = os.path.join(folder_path, file)\n",
        "      df = pd.read_parquet(file_path)\n",
        "      dfs.append(df)\n",
        "\n",
        "  entire_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  return entire_df\n",
        "\n",
        "history_df = get_full_df(\"history.parquet\")\n",
        "items_df = get_full_df(\"items.parquet\")\n",
        "users_df = get_full_df(\"users.parquet\")"
      ],
      "metadata": {
        "id": "g_0yaWAs7duo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_interactions = history_df.groupby('user_idx').size().rename('total_interactions')\n",
        "users_df = users_df.merge(user_interactions, on='user_idx', how='left').fillna(0)\n",
        "pos_rate = history_df.groupby('user_idx')['relevance'].mean().rename('positive_rate')\n",
        "users_df = users_df.merge(pos_rate, on='user_idx', how='left').fillna(0)"
      ],
      "metadata": {
        "id": "IR4JZ_vPnkHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_popularity = history_df.groupby('item_idx').size().rename('popularity')\n",
        "items_df = items_df.merge(item_popularity, on='item_idx', how='left').fillna(0)"
      ],
      "metadata": {
        "id": "yVB9l8e-nmw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Normalization (attr_ features looks normalized but also normalize them for sanity checks)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Identify user and item feature columns (excluding indices and categorical)\n",
        "user_feat_cols = [col for col in users_df.columns if col.startswith('user_attr_')] + [\"total_interactions\", \"positive_rate\"]\n",
        "item_feat_cols = [col for col in items_df.columns if col.startswith('item_attr_')] + ['price', 'popularity']\n",
        "\n",
        "user_scaler = StandardScaler()\n",
        "item_scaler = StandardScaler()\n",
        "\n",
        "users_df[user_feat_cols] = user_scaler.fit_transform(users_df[user_feat_cols])\n",
        "items_df[item_feat_cols] = item_scaler.fit_transform(items_df[item_feat_cols])"
      ],
      "metadata": {
        "id": "FPpk82aEnnIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = history_df.merge(users_df, on='user_idx', how='left')\n",
        "data = data.merge(items_df, on='item_idx', how='left')"
      ],
      "metadata": {
        "id": "oGlPEWzUnwlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "users_df = pd.get_dummies(users_df, columns=['segment'], drop_first=True)\n",
        "items_df = pd.get_dummies(items_df, columns=['category'], drop_first=True)"
      ],
      "metadata": {
        "id": "MXuyHWmkny3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFiJ46minzYd",
        "outputId": "3a347924-7960-4549-f16b-7d8b5664b03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_idx', 'item_idx', 'relevance', 'user_attr_0', 'user_attr_1',\n",
              "       'user_attr_2', 'user_attr_3', 'user_attr_4', 'user_attr_5',\n",
              "       'user_attr_6', 'user_attr_7', 'user_attr_8', 'user_attr_9',\n",
              "       'user_attr_10', 'user_attr_11', 'user_attr_12', 'user_attr_13',\n",
              "       'user_attr_14', 'user_attr_15', 'user_attr_16', 'user_attr_17',\n",
              "       'user_attr_18', 'user_attr_19', 'total_interactions', 'positive_rate',\n",
              "       'item_attr_0', 'item_attr_1', 'item_attr_2', 'item_attr_3',\n",
              "       'item_attr_4', 'item_attr_5', 'item_attr_6', 'item_attr_7',\n",
              "       'item_attr_8', 'item_attr_9', 'item_attr_10', 'item_attr_11',\n",
              "       'item_attr_12', 'item_attr_13', 'item_attr_14', 'item_attr_15',\n",
              "       'item_attr_16', 'item_attr_17', 'item_attr_18', 'item_attr_19', 'price',\n",
              "       'popularity', 'segment_mainstream', 'segment_premium',\n",
              "       'category_clothing', 'category_electronics', 'category_home'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = data"
      ],
      "metadata": {
        "id": "zj4cqwxUGOwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "user_features = combined_df.drop_duplicates(\"user_idx\").sort_values(\"user_idx\")[[\n",
        "    f\"user_attr_{i}\" for i in range(20)\n",
        "] + [\"total_interactions\", \"positive_rate\"]].values\n",
        "\n",
        "item_features_df = combined_df.drop_duplicates(\"item_idx\").sort_values(\"item_idx\")[[\n",
        "    f\"item_attr_{i}\" for i in range(20)\n",
        "] + [\"price\", \"popularity\", \"segment_mainstream\", \"segment_premium\",\n",
        "     \"category_clothing\", \"category_electronics\", \"category_home\"]]\n",
        "\n",
        "item_features_df = item_features_df.astype(float)\n",
        "\n",
        "user_tensor = torch.tensor(user_features, dtype=torch.float)\n",
        "item_tensor = torch.tensor(item_features_df.values, dtype=torch.float)"
      ],
      "metadata": {
        "id": "_PQzssvVoj5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = torch.tensor(combined_df[[\"user_idx\", \"item_idx\"]].values.T, dtype=torch.long)\n",
        "edge_label = torch.tensor(combined_df[\"relevance\"].values, dtype=torch.float)"
      ],
      "metadata": {
        "id": "U6hi23qp-mrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_user_ids = train_df[\"user_idx\"].unique()\n",
        "train_item_ids = train_df[\"item_idx\"].unique()\n",
        "num_users = len(users_df[\"user_idx\"].unique())\n",
        "num_items = len(items_df[\"item_idx\"].unique())"
      ],
      "metadata": {
        "id": "PEptIjs0abWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = HeteroData()\n",
        "\n",
        "# Node features\n",
        "data[\"user\"].x = user_tensor\n",
        "data[\"item\"].x = item_tensor\n",
        "\n",
        "# Edges\n",
        "data[\"user\", \"interacts\", \"item\"].edge_index = edge_index\n",
        "data[\"user\", \"interacts\", \"item\"].edge_label = edge_label\n",
        "\n",
        "# edge_attr\n",
        "# edge_attr_df = combined_df[[\"user_idx\", \"item_idx\", \"price\"]]\n",
        "# edge_attr = torch.tensor(edge_attr_df.values, dtype=torch.float)\n",
        "# data[\"user\", \"interacts\", \"item\"].edge_attr = edge_attr\n",
        "\n",
        "# Rev Edges\n",
        "data[\"item\", \"rev_interacts\", \"user\"].edge_index = edge_index.flip(0)\n",
        "data[\"item\", \"rev_interacts\", \"user\"].edge_label = edge_label"
      ],
      "metadata": {
        "id": "hhxG6eCF-n6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXENVadcfXNF",
        "outputId": "1a0f2fa8-1a72-4ca8-9167-4018445fdd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_idx', 'item_idx', 'relevance', 'user_attr_0', 'user_attr_1',\n",
              "       'user_attr_2', 'user_attr_3', 'user_attr_4', 'user_attr_5',\n",
              "       'user_attr_6', 'user_attr_7', 'user_attr_8', 'user_attr_9',\n",
              "       'user_attr_10', 'user_attr_11', 'user_attr_12', 'user_attr_13',\n",
              "       'user_attr_14', 'user_attr_15', 'user_attr_16', 'user_attr_17',\n",
              "       'user_attr_18', 'user_attr_19', 'total_interactions', 'positive_rate',\n",
              "       'item_attr_0', 'item_attr_1', 'item_attr_2', 'item_attr_3',\n",
              "       'item_attr_4', 'item_attr_5', 'item_attr_6', 'item_attr_7',\n",
              "       'item_attr_8', 'item_attr_9', 'item_attr_10', 'item_attr_11',\n",
              "       'item_attr_12', 'item_attr_13', 'item_attr_14', 'item_attr_15',\n",
              "       'item_attr_16', 'item_attr_17', 'item_attr_18', 'item_attr_19', 'price',\n",
              "       'popularity', 'segment_mainstream', 'segment_premium',\n",
              "       'category_clothing', 'category_electronics', 'category_home'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For train-test split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "edge_index_np = edge_index.cpu().numpy()\n",
        "edge_label_np = edge_label.cpu().numpy()\n",
        "\n",
        "edge_df = pd.DataFrame({\n",
        "    \"user_idx\": edge_index_np[0],\n",
        "    \"item_idx\": edge_index_np[1],\n",
        "    \"label\": edge_label_np\n",
        "})\n",
        "\n",
        "train_df, test_df = train_test_split(edge_df, test_size=0.2, stratify=edge_df[\"label\"], random_state=42)"
      ],
      "metadata": {
        "id": "mbHG5WjRWaGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add negative sampling to add negative edges\n",
        "def sample_negative_edges(train_df, num_users, num_items, num_samples):\n",
        "    existing = set((u, i) for u, i in zip(train_df[\"user_idx\"], train_df[\"item_idx\"]))\n",
        "    neg_edges = set()\n",
        "\n",
        "    while len(neg_edges) < num_samples:\n",
        "        u = np.random.randint(0, num_users)\n",
        "        i = np.random.randint(0, num_items)\n",
        "        if (u, i) not in existing:\n",
        "            neg_edges.add((u, i))\n",
        "\n",
        "    neg_df = pd.DataFrame(list(neg_edges), columns=[\"user_idx\", \"item_idx\"])\n",
        "    neg_df[\"label\"] = 0\n",
        "    return neg_df\n",
        "\n",
        "neg_df = sample_negative_edges(train_df, num_users, num_items, num_samples=len(train_df))\n",
        "train_df = pd.concat([train_df, neg_df]).sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "XCeBQ9r-aKAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_edge_index = torch.tensor(train_df[[\"user_idx\", \"item_idx\"]].values.T, dtype=torch.long)\n",
        "train_edge_label = torch.tensor(train_df[\"label\"].values, dtype=torch.float)\n",
        "\n",
        "data[\"user\", \"interacts\", \"item\"].edge_index = train_edge_index\n",
        "data[\"user\", \"interacts\", \"item\"].edge_label = train_edge_label\n",
        "\n",
        "data[\"item\", \"rev_interacts\", \"user\"].edge_index = train_edge_index.flip(0)\n",
        "data[\"item\", \"rev_interacts\", \"user\"].edge_label = train_edge_label"
      ],
      "metadata": {
        "id": "vIMvQ1tcaObr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, HeteroConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import BatchNorm1d\n",
        "\n",
        "class GraphSAGERecommender(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.bn_user = BatchNorm1d(hidden_dim)\n",
        "        self.bn_item = BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.conv1 = HeteroConv({\n",
        "            (\"user\", \"interacts\", \"item\"): SAGEConv((-1, -1), hidden_dim),\n",
        "            (\"item\", \"rev_interacts\", \"user\"): SAGEConv((-1, -1), hidden_dim),\n",
        "        }, aggr=\"sum\")\n",
        "\n",
        "        self.conv2 = HeteroConv({\n",
        "            (\"user\", \"interacts\", \"item\"): SAGEConv((hidden_dim, hidden_dim), hidden_dim),\n",
        "            (\"item\", \"rev_interacts\", \"user\"): SAGEConv((hidden_dim, hidden_dim), hidden_dim),\n",
        "        }, aggr=\"sum\")\n",
        "\n",
        "    def forward(self, data):\n",
        "        x_dict = self.conv1(data.x_dict, data.edge_index_dict)\n",
        "        x_dict[\"user\"] = self.bn_user(x_dict[\"user\"])\n",
        "        x_dict[\"item\"] = self.bn_item(x_dict[\"item\"])\n",
        "\n",
        "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
        "        x_dict = self.conv2(x_dict, data.edge_index_dict)\n",
        "        return x_dict\n"
      ],
      "metadata": {
        "id": "ys_JpjRXFPIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model = GraphSAGERecommender(hidden_dim=64)\n",
        "\n",
        "# weight_decay applies L2 regularization to all trainable params\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "for epoch in range(1, 151):\n",
        "    model.train()\n",
        "    out_dict = model(data)\n",
        "    user_emb = out_dict[\"user\"]\n",
        "    item_emb = out_dict[\"item\"]\n",
        "    edge_index = data[\"user\", \"interacts\", \"item\"].edge_index\n",
        "    edge_label = data[\"user\", \"interacts\", \"item\"].edge_label\n",
        "\n",
        "    # Predict link scores by dot product of user emb and item emb of the (user, item) as an edge\n",
        "    user_ids = edge_index[0]\n",
        "    item_ids = edge_index[1]\n",
        "    scores = (user_emb[user_ids] * item_emb[item_ids]).sum(dim=1)\n",
        "\n",
        "    loss = criterion(scores, edge_label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_prob = torch.sigmoid(scores)\n",
        "        pred_binary = (pred_prob > 0.5).float()\n",
        "        acc = (pred_binary == edge_label).float().mean().item()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch {epoch:02d}; Loss: {loss.item():.4f}; Acc: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2aDM1tWLkHy",
        "outputId": "66f8b2e9-4f23-4dc7-8ac5-0379b056f0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10; Loss: 1.0850; Acc: 0.4249\n",
            "Epoch 20; Loss: 0.6880; Acc: 0.6303\n",
            "Epoch 30; Loss: 0.5136; Acc: 0.7520\n",
            "Epoch 40; Loss: 0.5107; Acc: 0.7528\n",
            "Epoch 50; Loss: 0.4902; Acc: 0.7534\n",
            "Epoch 60; Loss: 0.4779; Acc: 0.7551\n",
            "Epoch 70; Loss: 0.4720; Acc: 0.7564\n",
            "Epoch 80; Loss: 0.4656; Acc: 0.7583\n",
            "Epoch 90; Loss: 0.4608; Acc: 0.7598\n",
            "Epoch 100; Loss: 0.4564; Acc: 0.7607\n",
            "Epoch 110; Loss: 0.4525; Acc: 0.7624\n",
            "Epoch 120; Loss: 0.4491; Acc: 0.7642\n",
            "Epoch 130; Loss: 0.4460; Acc: 0.7650\n",
            "Epoch 140; Loss: 0.4432; Acc: 0.7665\n",
            "Epoch 150; Loss: 0.4407; Acc: 0.7680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_graph_with_new_edges(data, new_df):\n",
        "    \"\"\"\n",
        "    Updates a HeteroData graph with new user-item interactions.\n",
        "    Assumes new_df has columns: ['user_idx', 'item_idx', 'label']\n",
        "    \"\"\"\n",
        "    new_edge_index = torch.tensor(new_df[[\"user_idx\", \"item_idx\"]].values.T, dtype=torch.long)\n",
        "    new_edge_label = torch.tensor(new_df[\"label\"].values, dtype=torch.float)\n",
        "\n",
        "    # Append to current edge_index and edge_label\n",
        "    old_edge_index = data[\"user\", \"interacts\", \"item\"].edge_index\n",
        "    old_edge_label = data[\"user\", \"interacts\", \"item\"].edge_label\n",
        "\n",
        "    data[\"user\", \"interacts\", \"item\"].edge_index = torch.cat([old_edge_index, new_edge_index], dim=1)\n",
        "    data[\"user\", \"interacts\", \"item\"].edge_label = torch.cat([old_edge_label, new_edge_label], dim=0)\n",
        "\n",
        "    # Reverse edge: item â†’ user\n",
        "    data[\"item\", \"rev_interacts\", \"user\"].edge_index = data[\"user\", \"interacts\", \"item\"].edge_index.flip(0)\n",
        "    data[\"item\", \"rev_interacts\", \"user\"].edge_label = data[\"user\", \"interacts\", \"item\"].edge_label\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "c1k8sxD3ctyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only deal with seen users and items during inference time\n",
        "\n",
        "test_df = test_df[\n",
        "    test_df[\"user_idx\"].isin(train_user_ids) &\n",
        "    test_df[\"item_idx\"].isin(train_item_ids)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Start test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data)\n",
        "    user_emb = out[\"user\"]\n",
        "    item_emb = out[\"item\"]\n",
        "\n",
        "test_user_ids = torch.tensor(test_df[\"user_idx\"].values, dtype=torch.long)\n",
        "test_item_ids = torch.tensor(test_df[\"item_idx\"].values, dtype=torch.long)\n",
        "test_labels   = torch.tensor(test_df[\"label\"].values, dtype=torch.float)\n",
        "\n",
        "test_scores = (user_emb[test_user_ids] * item_emb[test_item_ids]).sum(dim=1)\n",
        "test_probs = torch.sigmoid(test_scores)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc = roc_auc_score(test_labels.numpy(), test_probs.numpy())\n",
        "print(f\"Test AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUtzTe4qXZjQ",
        "outputId": "3d691326-85d0-4e17-bf29-41af4485fbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.9229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ranking with expected revenue\n",
        "def rank_items(user_emb, item_emb, prices, top_k=10):\n",
        "    scores = torch.matmul(user_emb, item_emb.T)\n",
        "    expected_revenue = scores * prices\n",
        "    top_items = torch.topk(expected_revenue, top_k, dim=1).indices\n",
        "    return top_items"
      ],
      "metadata": {
        "id": "8X9xM-AKH_de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices = data[\"item\"].x[:, -7]\n",
        "topk_recommendations = rank_items(user_emb, item_emb, prices, top_k=10)"
      ],
      "metadata": {
        "id": "ZgeVc_KJj6FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topk_recommendations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFTEy4zjZVx3",
        "outputId": "180e967b-a836-4aee-a57f-f5ddfb2232a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[129, 167, 986,  ..., 838, 941, 548],\n",
              "        [129,  48, 897,  ..., 167, 618, 871],\n",
              "        [987,  42, 142,  ..., 922, 141, 835],\n",
              "        ...,\n",
              "        [ 99, 559, 167,  ...,  52, 443, 958],\n",
              "        [ 99, 604, 817,  ..., 904, 559, 608],\n",
              "        [277, 676, 320,  ..., 572, 474, 442]])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j0EyRe9wgmPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}